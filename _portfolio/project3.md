---
title: Homework nÂ°4
subtitle: Statistical independence and SDE simulator used to represent the scaling limit of the random Walk
image: /assets/img/portfolio/continuous.jpg
alt: SDE

caption:
  title: Homework 4
  subtitle: Continuous time process simulator
  thumbnail: /assets/img/portfolio/continuous.jpg
---

# **Statistical Independence**

Statistical independence is a fundamental concept in probability theory, describing a situation where the occurrence of one event does not affect the occurrence of another. Imagine flipping a coin twice. The outcome of the first flip (heads or tails) doesn't influence the outcome of the second flip. These events are considered independent. 

Imagine flipping a coin twice. The outcome of the first flip (heads or tails) doesn't influence the outcome of the second flip. These events are considered independent. Two events $$A$$ and $$B$$ are said to be independent if the probability of their intersection is equal to the product of their individual probabilities:

$$P(A \cap B) = P(A) \cdot P(B)$$

Key Points About Independence:

Events are independent if knowledge of one event doesn't affect the probability of the other

Independent events may still occur together, but their co-occurrence is purely random

Independence is symmetric: if A is independent of B, then B is independent of A


Another way to express independence is through conditional probability. If $$A$$ and $$B$$ are independent, then:

$$P(A \mid B) = P(A)$$

And similarly:

$$P(B \mid A) = P(B)$$

For dependent events, the conditional probability would differ from the unconditional probability, indicating that the occurrence of one event gives information about the other.

From a distributional perspective, when two random variables are independent, their marginal distributions do not affect each other. This means that to find their joint distribution, you can simply multiply their marginal distributions.

# **Practical Part**







{:.list-inline}

- Date: 30 October 2024